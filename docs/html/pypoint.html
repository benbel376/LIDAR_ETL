<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.10.0" />
<title>pypoint API documentation</title>
<meta name="description" content="" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>pypoint</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">import pdal
import json
import geopandas
import pandas as pd
from shapely.geometry import Polygon, Point, mapping
import numpy as np
from pyproj import Proj, transform
import folium
import laspy as lp
import richdem as rd
import rasterio
import math
from scipy.interpolate import griddata
from rasterio.transform import Affine
from rasterio.crs import CRS
import urllib.request, json 
import warnings
import matplotlib.pyplot as plt
warnings.filterwarnings(&#34;ignore&#34;)
import sys

sys.path.append(&#34;.&#34;)
sys.path.append(&#34;..&#34;)
from scripts import util
utility = util.Util()

class Pypoint: 
    &#34;&#34;&#34;
    class that provides data fetching, transforming, and visualization functionalities
    
    &#34;&#34;&#34;
    
    def fetch_data(self, coordinates, 
                   meta_path,
                   save_path,
                   pipeline, 
                   epsg=[3857, 4326], 
                   url=&#39;https://s3-us-west-2.amazonaws.com/usgs-lidar-public/&#39;):
        &#34;&#34;&#34;
        loads data by taking path and epsg informations
        
        param:
        
            meta_path: the location of the metadata
            
            save_path: the location to save fetched data
            
            pipeline: the loction of the pdal pipeline json file
            
            epsg: a list of epsg files that hold original and new epsg values
            
            url: url to fetch the data from
            
        return: geopandas dataframe with elevation and location varibles
        &#34;&#34;&#34;
        
        coor = utility.loop_EPSG_converter(coordinates, epsg[1], epsg[0])
        polygon = utility.generate_polygon(coor, epsg[0])

        selection = utility.compare(meta_path, coor)

        print(f&#34;Selected Regions: {selection[0]}&#34;)

        data = self.load_full_data(selection, url, save_path, polygon, pipeline, epsg)

        return data

    

    def load_full_data(self, selection_list, url, path, polygon, json_location, epsg):
        &#34;&#34;&#34; 
        loads data by taking selection information.
        
        params:
        
            selection_list: a list that contains region names and their boundaries
            
            url: url to fetch the data from
            
            path: the path to save the data to.
            
            polygon: the selection boundary in polygon form
            
            json_location: the location of pdal pipeline json
            
            epsg: a list: [from, to]
        
        return: geopandas dataframe.
        
        &#34;&#34;&#34;
        
        
        regions = selection_list[0]
        bounds = selection_list[1]

        data = {}
        url = url
        for i in range(len(regions)):
            try:
                year = int(regions[i][-4:])
            except ValueError:
                year = None
            region = regions[i]
            furl = url+region+&#34;ept.json&#34;
            request = utility.modify_pipe_json(json_location, furl, path, epsg[0], epsg[1], polygon, bounds[i])
            pipe = pdal.Pipeline(json.dumps(request))
            num = pipe.execute()
            print(f&#34;Number of loadded points: {num}&#34;)
            df = self.generate_geo_df(pipe.arrays[0], epsg[1])
            data[&#34;year&#34;] = f&#34;{year}&#34;
            data[&#34;data&#34;] = df

        return pd.DataFrame([data])

    def generate_geo_df(self, pipe, epsg):
        &#34;&#34;&#34; 
        Turns an array into a geopandas dataframe.
        
        params: 
        
            pipe: pdal pipeline object
            
            epsg: from and to epsg formats
            
        return: a geopandas dataframe.
        &#34;&#34;&#34;
        try:
            cloud_points = []
            elevations =[]
            geometry_points=[]
            for row in pipe:
                lst = row.tolist()[-3:]
                cloud_points.append(lst)
                elevations.append(lst[2])
                point = Point(lst[0], lst[1])
                geometry_points.append(point)
            geodf = geopandas.GeoDataFrame(columns=[&#34;elevation&#34;, &#34;geometry&#34;])
            geodf[&#39;elevation&#39;] = elevations
            geodf[&#39;geometry&#39;] = geometry_points
            geodf = geodf.set_geometry(&#34;geometry&#34;)
            geodf.set_crs(epsg = epsg, inplace=True)
            return geodf
        except RuntimeError as e:
            self.logger.exception(&#39;fails to extract geo data frame&#39;)
            print(e)


    
    def calculate_TWI(self, df, prec = 0.000001, epsg = 4326, save_slope=None, save_accum=None):
        &#34;&#34;&#34; calculates topographic wetness index based on slope and accmulation results.
        
        params: 
        
            df: the dataframe that holds the point cloud.
            
            prec: the precision for interpolation
            
            epsg: the final epsg format
            
            save_slope: a location to save the generated slope image
            
            save_accum: a location to save the accummulation image
            
        return: a new dataframe with TWI column added
        
        &#34;&#34;&#34;
        
        in_df = df.copy()
        points = list(zip(in_df.geometry.x, in_df.geometry.y))
        values = in_df.elevation.values

        rRes = prec

        xRange = np.arange(in_df.geometry.x.min(), in_df.geometry.x.max()+rRes, rRes)
        yRange = np.arange(in_df.geometry.y.min(), in_df.geometry.y.max()+rRes, rRes)

        gridX, gridY = np.meshgrid(xRange, yRange)

        gridph = griddata(points, values, (gridX,gridY), method=&#39;cubic&#39;)

        transform = Affine.translation(gridX[0][0]-rRes/2, gridY[0][0]-rRes/2)*Affine.scale(rRes, rRes)
        transform

        rasterCrs = CRS.from_epsg(epsg)
        rasterCrs.data

        interpRaster = rasterio.open(&#39;raster.tif&#39;,
                                 &#39;w&#39;,
                                 driver=&#39;GTiff&#39;,
                                 height=gridph.shape[0],
                                 width=gridph.shape[1],
                                 count=1,
                                 dtype=gridph.dtype,
                                 crs=rasterCrs,
                                 transform=transform,
                                )
        interpRaster.write(gridph,1)
        interpRaster.close()

        dataset = rasterio.open(&#39;raster.tif&#39;)

        data = dataset.read()

        data = np.squeeze(data)
        #data = np.nan_to_num(data, nan=-9999)
        sp_dem = rd.rdarray(data, no_data=-9999)

        slope = rd.TerrainAttribute(sp_dem, attrib=&#39;slope_riserun&#39;)
        if save_slope is not None:
            slope_pic = rd.rdShow(slope, axes=True, cmap=&#39;magma&#39;, figsize=(10, 5))
            plt.savefig(save_slope)

        accum_d8 = rd.FlowAccumulation(sp_dem, method=&#39;D8&#39;)
        if save_accum is not None:
            d8_fig = rd.rdShow(accum_d8,figsize=(10,5), axes=False, cmap=&#39;jet&#39;)
            plt.savefig(save_accum)

        slope_l = []
        accum_l = []
        for point in in_df[&#39;geometry&#39;]:
            x = point.xy[0][0]
            y = point.xy[1][0]
            row, col = dataset.index(x,y)
            slope_l.append(slope[row,col])
            accum_l.append(accum_d8[row,col])

        TWI = []

        for i in range(len(slope_l)):
            TWI.append(np.log(abs((accum_l[i]/math.tan((slope_l[i]* math.pi/180.0))))))

        in_df[&#34;TWI&#34;] = TWI

        return in_df
    
    
    
    
    def render_3d(self, df, title, path, s: float = 0.01) -&gt; None:
        &#34;&#34;&#34; Plots a 3D terrain scatter plot for the cloud data points of geopandas data frame using matplotlib
        
        params:
        
            df: the data
            
            title: the title for generated image
            
            path: path to save the generated image
            
            s: precision.
            
        return: none.
        &#34;&#34;&#34;

        fig, ax = plt.subplots(1, 1, figsize=(12, 10))
        ax = plt.axes(projection=&#39;3d&#39;)
        ax.scatter(df.geometry.x, df.geometry.y, df.elevation.values, s=s)
        ax.set_xlabel(&#39;Longitude&#39;)
        ax.set_ylabel(&#39;Latitude&#39;)
        plt.title(title)
        plt.savefig(f&#34;{path}&#34;, dpi=120)
        plt.show()


    def plot_heatmap(self, df, title, path) -&gt; None:
        &#34;&#34;&#34; Plots a 2D heat map for the point cloud data using matplotlib
        
        params: 
        
            df: the data.
            
            title: the title for the image to be generated.
            
            path: the path to save the image to be generated.
            
        returns: None.
        &#34;&#34;&#34;

        fig, ax = plt.subplots(1, 1, figsize=(12, 10))
        df.plot(column=&#39;elevation&#39;, ax=ax, legend=True, cmap=&#34;terrain&#34;)
        plt.title(title)
        plt.xlabel(&#39;Longitude&#39;)
        plt.ylabel(&#39;Latitude&#39;)
        plt.savefig(f&#34;{path}&#34;, dpi=120)
        plt.show()
        
        
    def grid_resample(self, df,size, epsg=4326):
        &#34;&#34;&#34; resamples points using grid method
        
        Args: 
        
            df: the data
            
            size: the size of voxels
            
            epsg: the final epsg
            
        Returns: resampled dataframe.
        
        
        &#34;&#34;&#34;
        newdf = df.copy()
        points1 = list(zip(newdf.geometry.x, newdf.geometry.y, newdf.elevation.values))

        voxel_size=size
        nb_vox=np.ceil((np.max(points1, axis=0) - np.min(points1, axis=0))/voxel_size)
        nb_vox

        non_empty_voxel_keys, inverse, nb_pts_per_voxel = np.unique(((points1 - np.min(points1, axis=0)) 
                                                                     // voxel_size).astype(int), axis=0, 
                                                                    return_inverse=True, return_counts=True)
        idx_pts_vox_sorted=np.argsort(inverse)

        voxel_grid={}
        grid_barycenter,grid_candidate_center=[],[]
        last_seen=0
        points_new = []
        for item in points1:
            tmp = []
            for it in item:
                tmp.append(it)
            points_new.append(tmp)

        points_new = np.array(points_new)

        for idx,vox in enumerate(non_empty_voxel_keys):
            voxel_grid[tuple(vox)]= points_new[idx_pts_vox_sorted[last_seen:last_seen+nb_pts_per_voxel[idx]]]
            nval = np.mean(voxel_grid[tuple(vox)],axis=0)
            grid_barycenter.append(nval)
            grid_candidate_center.append(
                voxel_grid[tuple(vox)][np.linalg.norm(voxel_grid[tuple(vox)] 
                                                      - np.mean(voxel_grid[tuple(vox)],axis=0),axis=1).argmin()])
            last_seen+=nb_pts_per_voxel[idx]

        df22 = self.generate_geo_df(grid_barycenter, epsg)

        return df22</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="pypoint.Pypoint"><code class="flex name class">
<span>class <span class="ident">Pypoint</span></span>
</code></dt>
<dd>
<div class="desc"><p>class that provides data fetching, transforming, and visualization functionalities</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class Pypoint: 
    &#34;&#34;&#34;
    class that provides data fetching, transforming, and visualization functionalities
    
    &#34;&#34;&#34;
    
    def fetch_data(self, coordinates, 
                   meta_path,
                   save_path,
                   pipeline, 
                   epsg=[3857, 4326], 
                   url=&#39;https://s3-us-west-2.amazonaws.com/usgs-lidar-public/&#39;):
        &#34;&#34;&#34;
        loads data by taking path and epsg informations
        
        param:
        
            meta_path: the location of the metadata
            
            save_path: the location to save fetched data
            
            pipeline: the loction of the pdal pipeline json file
            
            epsg: a list of epsg files that hold original and new epsg values
            
            url: url to fetch the data from
            
        return: geopandas dataframe with elevation and location varibles
        &#34;&#34;&#34;
        
        coor = utility.loop_EPSG_converter(coordinates, epsg[1], epsg[0])
        polygon = utility.generate_polygon(coor, epsg[0])

        selection = utility.compare(meta_path, coor)

        print(f&#34;Selected Regions: {selection[0]}&#34;)

        data = self.load_full_data(selection, url, save_path, polygon, pipeline, epsg)

        return data

    

    def load_full_data(self, selection_list, url, path, polygon, json_location, epsg):
        &#34;&#34;&#34; 
        loads data by taking selection information.
        
        params:
        
            selection_list: a list that contains region names and their boundaries
            
            url: url to fetch the data from
            
            path: the path to save the data to.
            
            polygon: the selection boundary in polygon form
            
            json_location: the location of pdal pipeline json
            
            epsg: a list: [from, to]
        
        return: geopandas dataframe.
        
        &#34;&#34;&#34;
        
        
        regions = selection_list[0]
        bounds = selection_list[1]

        data = {}
        url = url
        for i in range(len(regions)):
            try:
                year = int(regions[i][-4:])
            except ValueError:
                year = None
            region = regions[i]
            furl = url+region+&#34;ept.json&#34;
            request = utility.modify_pipe_json(json_location, furl, path, epsg[0], epsg[1], polygon, bounds[i])
            pipe = pdal.Pipeline(json.dumps(request))
            num = pipe.execute()
            print(f&#34;Number of loadded points: {num}&#34;)
            df = self.generate_geo_df(pipe.arrays[0], epsg[1])
            data[&#34;year&#34;] = f&#34;{year}&#34;
            data[&#34;data&#34;] = df

        return pd.DataFrame([data])

    def generate_geo_df(self, pipe, epsg):
        &#34;&#34;&#34; 
        Turns an array into a geopandas dataframe.
        
        params: 
        
            pipe: pdal pipeline object
            
            epsg: from and to epsg formats
            
        return: a geopandas dataframe.
        &#34;&#34;&#34;
        try:
            cloud_points = []
            elevations =[]
            geometry_points=[]
            for row in pipe:
                lst = row.tolist()[-3:]
                cloud_points.append(lst)
                elevations.append(lst[2])
                point = Point(lst[0], lst[1])
                geometry_points.append(point)
            geodf = geopandas.GeoDataFrame(columns=[&#34;elevation&#34;, &#34;geometry&#34;])
            geodf[&#39;elevation&#39;] = elevations
            geodf[&#39;geometry&#39;] = geometry_points
            geodf = geodf.set_geometry(&#34;geometry&#34;)
            geodf.set_crs(epsg = epsg, inplace=True)
            return geodf
        except RuntimeError as e:
            self.logger.exception(&#39;fails to extract geo data frame&#39;)
            print(e)


    
    def calculate_TWI(self, df, prec = 0.000001, epsg = 4326, save_slope=None, save_accum=None):
        &#34;&#34;&#34; calculates topographic wetness index based on slope and accmulation results.
        
        params: 
        
            df: the dataframe that holds the point cloud.
            
            prec: the precision for interpolation
            
            epsg: the final epsg format
            
            save_slope: a location to save the generated slope image
            
            save_accum: a location to save the accummulation image
            
        return: a new dataframe with TWI column added
        
        &#34;&#34;&#34;
        
        in_df = df.copy()
        points = list(zip(in_df.geometry.x, in_df.geometry.y))
        values = in_df.elevation.values

        rRes = prec

        xRange = np.arange(in_df.geometry.x.min(), in_df.geometry.x.max()+rRes, rRes)
        yRange = np.arange(in_df.geometry.y.min(), in_df.geometry.y.max()+rRes, rRes)

        gridX, gridY = np.meshgrid(xRange, yRange)

        gridph = griddata(points, values, (gridX,gridY), method=&#39;cubic&#39;)

        transform = Affine.translation(gridX[0][0]-rRes/2, gridY[0][0]-rRes/2)*Affine.scale(rRes, rRes)
        transform

        rasterCrs = CRS.from_epsg(epsg)
        rasterCrs.data

        interpRaster = rasterio.open(&#39;raster.tif&#39;,
                                 &#39;w&#39;,
                                 driver=&#39;GTiff&#39;,
                                 height=gridph.shape[0],
                                 width=gridph.shape[1],
                                 count=1,
                                 dtype=gridph.dtype,
                                 crs=rasterCrs,
                                 transform=transform,
                                )
        interpRaster.write(gridph,1)
        interpRaster.close()

        dataset = rasterio.open(&#39;raster.tif&#39;)

        data = dataset.read()

        data = np.squeeze(data)
        #data = np.nan_to_num(data, nan=-9999)
        sp_dem = rd.rdarray(data, no_data=-9999)

        slope = rd.TerrainAttribute(sp_dem, attrib=&#39;slope_riserun&#39;)
        if save_slope is not None:
            slope_pic = rd.rdShow(slope, axes=True, cmap=&#39;magma&#39;, figsize=(10, 5))
            plt.savefig(save_slope)

        accum_d8 = rd.FlowAccumulation(sp_dem, method=&#39;D8&#39;)
        if save_accum is not None:
            d8_fig = rd.rdShow(accum_d8,figsize=(10,5), axes=False, cmap=&#39;jet&#39;)
            plt.savefig(save_accum)

        slope_l = []
        accum_l = []
        for point in in_df[&#39;geometry&#39;]:
            x = point.xy[0][0]
            y = point.xy[1][0]
            row, col = dataset.index(x,y)
            slope_l.append(slope[row,col])
            accum_l.append(accum_d8[row,col])

        TWI = []

        for i in range(len(slope_l)):
            TWI.append(np.log(abs((accum_l[i]/math.tan((slope_l[i]* math.pi/180.0))))))

        in_df[&#34;TWI&#34;] = TWI

        return in_df
    
    
    
    
    def render_3d(self, df, title, path, s: float = 0.01) -&gt; None:
        &#34;&#34;&#34; Plots a 3D terrain scatter plot for the cloud data points of geopandas data frame using matplotlib
        
        params:
        
            df: the data
            
            title: the title for generated image
            
            path: path to save the generated image
            
            s: precision.
            
        return: none.
        &#34;&#34;&#34;

        fig, ax = plt.subplots(1, 1, figsize=(12, 10))
        ax = plt.axes(projection=&#39;3d&#39;)
        ax.scatter(df.geometry.x, df.geometry.y, df.elevation.values, s=s)
        ax.set_xlabel(&#39;Longitude&#39;)
        ax.set_ylabel(&#39;Latitude&#39;)
        plt.title(title)
        plt.savefig(f&#34;{path}&#34;, dpi=120)
        plt.show()


    def plot_heatmap(self, df, title, path) -&gt; None:
        &#34;&#34;&#34; Plots a 2D heat map for the point cloud data using matplotlib
        
        params: 
        
            df: the data.
            
            title: the title for the image to be generated.
            
            path: the path to save the image to be generated.
            
        returns: None.
        &#34;&#34;&#34;

        fig, ax = plt.subplots(1, 1, figsize=(12, 10))
        df.plot(column=&#39;elevation&#39;, ax=ax, legend=True, cmap=&#34;terrain&#34;)
        plt.title(title)
        plt.xlabel(&#39;Longitude&#39;)
        plt.ylabel(&#39;Latitude&#39;)
        plt.savefig(f&#34;{path}&#34;, dpi=120)
        plt.show()
        
        
    def grid_resample(self, df,size, epsg=4326):
        &#34;&#34;&#34; resamples points using grid method
        
        Args: 
        
            df: the data
            
            size: the size of voxels
            
            epsg: the final epsg
            
        Returns: resampled dataframe.
        
        
        &#34;&#34;&#34;
        newdf = df.copy()
        points1 = list(zip(newdf.geometry.x, newdf.geometry.y, newdf.elevation.values))

        voxel_size=size
        nb_vox=np.ceil((np.max(points1, axis=0) - np.min(points1, axis=0))/voxel_size)
        nb_vox

        non_empty_voxel_keys, inverse, nb_pts_per_voxel = np.unique(((points1 - np.min(points1, axis=0)) 
                                                                     // voxel_size).astype(int), axis=0, 
                                                                    return_inverse=True, return_counts=True)
        idx_pts_vox_sorted=np.argsort(inverse)

        voxel_grid={}
        grid_barycenter,grid_candidate_center=[],[]
        last_seen=0
        points_new = []
        for item in points1:
            tmp = []
            for it in item:
                tmp.append(it)
            points_new.append(tmp)

        points_new = np.array(points_new)

        for idx,vox in enumerate(non_empty_voxel_keys):
            voxel_grid[tuple(vox)]= points_new[idx_pts_vox_sorted[last_seen:last_seen+nb_pts_per_voxel[idx]]]
            nval = np.mean(voxel_grid[tuple(vox)],axis=0)
            grid_barycenter.append(nval)
            grid_candidate_center.append(
                voxel_grid[tuple(vox)][np.linalg.norm(voxel_grid[tuple(vox)] 
                                                      - np.mean(voxel_grid[tuple(vox)],axis=0),axis=1).argmin()])
            last_seen+=nb_pts_per_voxel[idx]

        df22 = self.generate_geo_df(grid_barycenter, epsg)

        return df22</code></pre>
</details>
<h3>Methods</h3>
<dl>
<dt id="pypoint.Pypoint.calculate_TWI"><code class="name flex">
<span>def <span class="ident">calculate_TWI</span></span>(<span>self, df, prec=1e-06, epsg=4326, save_slope=None, save_accum=None)</span>
</code></dt>
<dd>
<div class="desc"><p>calculates topographic wetness index based on slope and accmulation results.</p>
<p>params: </p>
<pre><code>df: the dataframe that holds the point cloud.

prec: the precision for interpolation

epsg: the final epsg format

save_slope: a location to save the generated slope image

save_accum: a location to save the accummulation image
</code></pre>
<p>return: a new dataframe with TWI column added</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def calculate_TWI(self, df, prec = 0.000001, epsg = 4326, save_slope=None, save_accum=None):
    &#34;&#34;&#34; calculates topographic wetness index based on slope and accmulation results.
    
    params: 
    
        df: the dataframe that holds the point cloud.
        
        prec: the precision for interpolation
        
        epsg: the final epsg format
        
        save_slope: a location to save the generated slope image
        
        save_accum: a location to save the accummulation image
        
    return: a new dataframe with TWI column added
    
    &#34;&#34;&#34;
    
    in_df = df.copy()
    points = list(zip(in_df.geometry.x, in_df.geometry.y))
    values = in_df.elevation.values

    rRes = prec

    xRange = np.arange(in_df.geometry.x.min(), in_df.geometry.x.max()+rRes, rRes)
    yRange = np.arange(in_df.geometry.y.min(), in_df.geometry.y.max()+rRes, rRes)

    gridX, gridY = np.meshgrid(xRange, yRange)

    gridph = griddata(points, values, (gridX,gridY), method=&#39;cubic&#39;)

    transform = Affine.translation(gridX[0][0]-rRes/2, gridY[0][0]-rRes/2)*Affine.scale(rRes, rRes)
    transform

    rasterCrs = CRS.from_epsg(epsg)
    rasterCrs.data

    interpRaster = rasterio.open(&#39;raster.tif&#39;,
                             &#39;w&#39;,
                             driver=&#39;GTiff&#39;,
                             height=gridph.shape[0],
                             width=gridph.shape[1],
                             count=1,
                             dtype=gridph.dtype,
                             crs=rasterCrs,
                             transform=transform,
                            )
    interpRaster.write(gridph,1)
    interpRaster.close()

    dataset = rasterio.open(&#39;raster.tif&#39;)

    data = dataset.read()

    data = np.squeeze(data)
    #data = np.nan_to_num(data, nan=-9999)
    sp_dem = rd.rdarray(data, no_data=-9999)

    slope = rd.TerrainAttribute(sp_dem, attrib=&#39;slope_riserun&#39;)
    if save_slope is not None:
        slope_pic = rd.rdShow(slope, axes=True, cmap=&#39;magma&#39;, figsize=(10, 5))
        plt.savefig(save_slope)

    accum_d8 = rd.FlowAccumulation(sp_dem, method=&#39;D8&#39;)
    if save_accum is not None:
        d8_fig = rd.rdShow(accum_d8,figsize=(10,5), axes=False, cmap=&#39;jet&#39;)
        plt.savefig(save_accum)

    slope_l = []
    accum_l = []
    for point in in_df[&#39;geometry&#39;]:
        x = point.xy[0][0]
        y = point.xy[1][0]
        row, col = dataset.index(x,y)
        slope_l.append(slope[row,col])
        accum_l.append(accum_d8[row,col])

    TWI = []

    for i in range(len(slope_l)):
        TWI.append(np.log(abs((accum_l[i]/math.tan((slope_l[i]* math.pi/180.0))))))

    in_df[&#34;TWI&#34;] = TWI

    return in_df</code></pre>
</details>
</dd>
<dt id="pypoint.Pypoint.fetch_data"><code class="name flex">
<span>def <span class="ident">fetch_data</span></span>(<span>self, coordinates, meta_path, save_path, pipeline, epsg=[3857, 4326], url='https://s3-us-west-2.amazonaws.com/usgs-lidar-public/')</span>
</code></dt>
<dd>
<div class="desc"><p>loads data by taking path and epsg informations</p>
<p>param:</p>
<pre><code>meta_path: the location of the metadata

save_path: the location to save fetched data

pipeline: the loction of the pdal pipeline json file

epsg: a list of epsg files that hold original and new epsg values

url: url to fetch the data from
</code></pre>
<p>return: geopandas dataframe with elevation and location varibles</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def fetch_data(self, coordinates, 
               meta_path,
               save_path,
               pipeline, 
               epsg=[3857, 4326], 
               url=&#39;https://s3-us-west-2.amazonaws.com/usgs-lidar-public/&#39;):
    &#34;&#34;&#34;
    loads data by taking path and epsg informations
    
    param:
    
        meta_path: the location of the metadata
        
        save_path: the location to save fetched data
        
        pipeline: the loction of the pdal pipeline json file
        
        epsg: a list of epsg files that hold original and new epsg values
        
        url: url to fetch the data from
        
    return: geopandas dataframe with elevation and location varibles
    &#34;&#34;&#34;
    
    coor = utility.loop_EPSG_converter(coordinates, epsg[1], epsg[0])
    polygon = utility.generate_polygon(coor, epsg[0])

    selection = utility.compare(meta_path, coor)

    print(f&#34;Selected Regions: {selection[0]}&#34;)

    data = self.load_full_data(selection, url, save_path, polygon, pipeline, epsg)

    return data</code></pre>
</details>
</dd>
<dt id="pypoint.Pypoint.generate_geo_df"><code class="name flex">
<span>def <span class="ident">generate_geo_df</span></span>(<span>self, pipe, epsg)</span>
</code></dt>
<dd>
<div class="desc"><p>Turns an array into a geopandas dataframe.</p>
<p>params: </p>
<pre><code>pipe: pdal pipeline object

epsg: from and to epsg formats
</code></pre>
<p>return: a geopandas dataframe.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def generate_geo_df(self, pipe, epsg):
    &#34;&#34;&#34; 
    Turns an array into a geopandas dataframe.
    
    params: 
    
        pipe: pdal pipeline object
        
        epsg: from and to epsg formats
        
    return: a geopandas dataframe.
    &#34;&#34;&#34;
    try:
        cloud_points = []
        elevations =[]
        geometry_points=[]
        for row in pipe:
            lst = row.tolist()[-3:]
            cloud_points.append(lst)
            elevations.append(lst[2])
            point = Point(lst[0], lst[1])
            geometry_points.append(point)
        geodf = geopandas.GeoDataFrame(columns=[&#34;elevation&#34;, &#34;geometry&#34;])
        geodf[&#39;elevation&#39;] = elevations
        geodf[&#39;geometry&#39;] = geometry_points
        geodf = geodf.set_geometry(&#34;geometry&#34;)
        geodf.set_crs(epsg = epsg, inplace=True)
        return geodf
    except RuntimeError as e:
        self.logger.exception(&#39;fails to extract geo data frame&#39;)
        print(e)</code></pre>
</details>
</dd>
<dt id="pypoint.Pypoint.grid_resample"><code class="name flex">
<span>def <span class="ident">grid_resample</span></span>(<span>self, df, size, epsg=4326)</span>
</code></dt>
<dd>
<div class="desc"><p>resamples points using grid method</p>
<p>Args: </p>
<pre><code>df: the data

size: the size of voxels

epsg: the final epsg
</code></pre>
<p>Returns: resampled dataframe.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def grid_resample(self, df,size, epsg=4326):
    &#34;&#34;&#34; resamples points using grid method
    
    Args: 
    
        df: the data
        
        size: the size of voxels
        
        epsg: the final epsg
        
    Returns: resampled dataframe.
    
    
    &#34;&#34;&#34;
    newdf = df.copy()
    points1 = list(zip(newdf.geometry.x, newdf.geometry.y, newdf.elevation.values))

    voxel_size=size
    nb_vox=np.ceil((np.max(points1, axis=0) - np.min(points1, axis=0))/voxel_size)
    nb_vox

    non_empty_voxel_keys, inverse, nb_pts_per_voxel = np.unique(((points1 - np.min(points1, axis=0)) 
                                                                 // voxel_size).astype(int), axis=0, 
                                                                return_inverse=True, return_counts=True)
    idx_pts_vox_sorted=np.argsort(inverse)

    voxel_grid={}
    grid_barycenter,grid_candidate_center=[],[]
    last_seen=0
    points_new = []
    for item in points1:
        tmp = []
        for it in item:
            tmp.append(it)
        points_new.append(tmp)

    points_new = np.array(points_new)

    for idx,vox in enumerate(non_empty_voxel_keys):
        voxel_grid[tuple(vox)]= points_new[idx_pts_vox_sorted[last_seen:last_seen+nb_pts_per_voxel[idx]]]
        nval = np.mean(voxel_grid[tuple(vox)],axis=0)
        grid_barycenter.append(nval)
        grid_candidate_center.append(
            voxel_grid[tuple(vox)][np.linalg.norm(voxel_grid[tuple(vox)] 
                                                  - np.mean(voxel_grid[tuple(vox)],axis=0),axis=1).argmin()])
        last_seen+=nb_pts_per_voxel[idx]

    df22 = self.generate_geo_df(grid_barycenter, epsg)

    return df22</code></pre>
</details>
</dd>
<dt id="pypoint.Pypoint.load_full_data"><code class="name flex">
<span>def <span class="ident">load_full_data</span></span>(<span>self, selection_list, url, path, polygon, json_location, epsg)</span>
</code></dt>
<dd>
<div class="desc"><p>loads data by taking selection information.</p>
<p>params:</p>
<pre><code>selection_list: a list that contains region names and their boundaries

url: url to fetch the data from

path: the path to save the data to.

polygon: the selection boundary in polygon form

json_location: the location of pdal pipeline json

epsg: a list: [from, to]
</code></pre>
<p>return: geopandas dataframe.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def load_full_data(self, selection_list, url, path, polygon, json_location, epsg):
    &#34;&#34;&#34; 
    loads data by taking selection information.
    
    params:
    
        selection_list: a list that contains region names and their boundaries
        
        url: url to fetch the data from
        
        path: the path to save the data to.
        
        polygon: the selection boundary in polygon form
        
        json_location: the location of pdal pipeline json
        
        epsg: a list: [from, to]
    
    return: geopandas dataframe.
    
    &#34;&#34;&#34;
    
    
    regions = selection_list[0]
    bounds = selection_list[1]

    data = {}
    url = url
    for i in range(len(regions)):
        try:
            year = int(regions[i][-4:])
        except ValueError:
            year = None
        region = regions[i]
        furl = url+region+&#34;ept.json&#34;
        request = utility.modify_pipe_json(json_location, furl, path, epsg[0], epsg[1], polygon, bounds[i])
        pipe = pdal.Pipeline(json.dumps(request))
        num = pipe.execute()
        print(f&#34;Number of loadded points: {num}&#34;)
        df = self.generate_geo_df(pipe.arrays[0], epsg[1])
        data[&#34;year&#34;] = f&#34;{year}&#34;
        data[&#34;data&#34;] = df

    return pd.DataFrame([data])</code></pre>
</details>
</dd>
<dt id="pypoint.Pypoint.plot_heatmap"><code class="name flex">
<span>def <span class="ident">plot_heatmap</span></span>(<span>self, df, title, path) ‑> None</span>
</code></dt>
<dd>
<div class="desc"><p>Plots a 2D heat map for the point cloud data using matplotlib</p>
<p>params: </p>
<pre><code>df: the data.

title: the title for the image to be generated.

path: the path to save the image to be generated.
</code></pre>
<p>returns: None.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def plot_heatmap(self, df, title, path) -&gt; None:
    &#34;&#34;&#34; Plots a 2D heat map for the point cloud data using matplotlib
    
    params: 
    
        df: the data.
        
        title: the title for the image to be generated.
        
        path: the path to save the image to be generated.
        
    returns: None.
    &#34;&#34;&#34;

    fig, ax = plt.subplots(1, 1, figsize=(12, 10))
    df.plot(column=&#39;elevation&#39;, ax=ax, legend=True, cmap=&#34;terrain&#34;)
    plt.title(title)
    plt.xlabel(&#39;Longitude&#39;)
    plt.ylabel(&#39;Latitude&#39;)
    plt.savefig(f&#34;{path}&#34;, dpi=120)
    plt.show()</code></pre>
</details>
</dd>
<dt id="pypoint.Pypoint.render_3d"><code class="name flex">
<span>def <span class="ident">render_3d</span></span>(<span>self, df, title, path, s: float = 0.01) ‑> None</span>
</code></dt>
<dd>
<div class="desc"><p>Plots a 3D terrain scatter plot for the cloud data points of geopandas data frame using matplotlib</p>
<p>params:</p>
<pre><code>df: the data

title: the title for generated image

path: path to save the generated image

s: precision.
</code></pre>
<p>return: none.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def render_3d(self, df, title, path, s: float = 0.01) -&gt; None:
    &#34;&#34;&#34; Plots a 3D terrain scatter plot for the cloud data points of geopandas data frame using matplotlib
    
    params:
    
        df: the data
        
        title: the title for generated image
        
        path: path to save the generated image
        
        s: precision.
        
    return: none.
    &#34;&#34;&#34;

    fig, ax = plt.subplots(1, 1, figsize=(12, 10))
    ax = plt.axes(projection=&#39;3d&#39;)
    ax.scatter(df.geometry.x, df.geometry.y, df.elevation.values, s=s)
    ax.set_xlabel(&#39;Longitude&#39;)
    ax.set_ylabel(&#39;Latitude&#39;)
    plt.title(title)
    plt.savefig(f&#34;{path}&#34;, dpi=120)
    plt.show()</code></pre>
</details>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="pypoint.Pypoint" href="#pypoint.Pypoint">Pypoint</a></code></h4>
<ul class="two-column">
<li><code><a title="pypoint.Pypoint.calculate_TWI" href="#pypoint.Pypoint.calculate_TWI">calculate_TWI</a></code></li>
<li><code><a title="pypoint.Pypoint.fetch_data" href="#pypoint.Pypoint.fetch_data">fetch_data</a></code></li>
<li><code><a title="pypoint.Pypoint.generate_geo_df" href="#pypoint.Pypoint.generate_geo_df">generate_geo_df</a></code></li>
<li><code><a title="pypoint.Pypoint.grid_resample" href="#pypoint.Pypoint.grid_resample">grid_resample</a></code></li>
<li><code><a title="pypoint.Pypoint.load_full_data" href="#pypoint.Pypoint.load_full_data">load_full_data</a></code></li>
<li><code><a title="pypoint.Pypoint.plot_heatmap" href="#pypoint.Pypoint.plot_heatmap">plot_heatmap</a></code></li>
<li><code><a title="pypoint.Pypoint.render_3d" href="#pypoint.Pypoint.render_3d">render_3d</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.10.0</a>.</p>
</footer>
</body>
</html>